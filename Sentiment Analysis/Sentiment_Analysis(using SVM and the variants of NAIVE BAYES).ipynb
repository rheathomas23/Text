{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/Users/rhea-8992/git_repo_changes made/Text'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import re\n",
    "from textblob import TextBlob\n",
    "from nltk.corpus import stopwords \n",
    "from sklearn import model_selection, preprocessing, naive_bayes, metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn import decomposition, ensemble\n",
    "import string\n",
    "from sklearn.externals import joblib\n",
    "from sklearn import svm\n",
    "import os\n",
    "from sklearn.model_selection import KFold \n",
    "current_path = os.getcwd()\n",
    "current_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sentiment_analysis:  \n",
    "    \n",
    "    # A pre-processing step to make the texts cleaner and easier to process and a vectorization step to transform these texts into numerical vectors.\n",
    "    def data_prep(self):\n",
    "        df = open(\"amazon_reviews.csv\").read() \n",
    "        data = df.split(\"\\n\")\n",
    "        labels, texts = [], []\n",
    "        for i, line in enumerate(data):\n",
    "            content = line.split()\n",
    "            labels.append(content[0])\n",
    "            texts.append(\" \".join(content[1:]))\n",
    "        d = {'Label':labels,'Reviews':texts}\n",
    "        df1 = pd.DataFrame(d)\n",
    "        return df1\n",
    "    \n",
    "    def data_preprocess(self): \n",
    "        df2 = self.data_prep()\n",
    "        # Removal of stopwords\n",
    "        stop = stopwords.words('english')\n",
    "        df2[\"Reviews\"] = df2[\"Reviews\"].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "        # Converting the reviews into lowercase\n",
    "        df2[\"Reviews\"] = df2[\"Reviews\"].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "        # Removing punctuation marks \n",
    "        df1[\"Reviews\"] = df1[\"Reviews\"].str.replace('[^\\w\\s]',' ')\n",
    "        # Rare words removal \n",
    "        freq = pd.Series(' '.join(df2[\"Reviews\"]).split()).value_counts()[-10:]\n",
    "        freq = list(freq.index)\n",
    "        df2[\"Reviews\"] = df2[\"Reviews\"].apply(lambda x: \" \".join(x for x in x.split() if x not in freq))\n",
    "        # Tokenization of text data \n",
    "        Token_list = []\n",
    "        for i in range(0, len(df2)):\n",
    "            Token_list.append(TextBlob(df2[\"Reviews\"][i]).words)\n",
    "        return Token_list\n",
    "\n",
    "    def split_data(self):\n",
    "        df2 = self.data_prep()\n",
    "        #splitting the dataset into training and validation datasets\n",
    "        train_x, valid_x, train_y, valid_y = model_selection.train_test_split(df2[\"Reviews\"], df2[\"Label\"], random_state = 42, test_size = 0.2)\n",
    "        # label encode the target variable\n",
    "        encoder = preprocessing.LabelEncoder()\n",
    "        train_y = encoder.fit_transform(train_y)\n",
    "        valid_y = encoder.fit_transform(valid_y)\n",
    "        count_vect = CountVectorizer(analyzer = 'word', token_pattern = r'\\w{1,}')\n",
    "        count_vect.fit(df2[\"Reviews\"])\n",
    "        #transform the training and validation data using count vectorizer object \n",
    "        xtrain_count =  count_vect.transform(train_x)\n",
    "        xvalid_count =  count_vect.transform(valid_x)\n",
    "        return xtrain_count, xvalid_count, train_y, valid_y, valid_x\n",
    "   \n",
    "    def train_model(self, classifier, feature_vector_train, label, feature_vector_valid ,valid_y):\n",
    "        # fit the training dataset on the classifier \n",
    "        t = feature_vector_train.toarray()\n",
    "        classifier.fit(t, label )\n",
    "        # predict the labels on validation dataset \n",
    "        predictions = classifier.predict(feature_vector_valid)\n",
    "        return metrics.accuracy_score(predictions, valid_y), metrics.f1_score(predictions, valid_y), classifier\n",
    "    \n",
    "    #MultinomialNB()\n",
    "    def prediction(self):\n",
    "        xtrain_count, xvalid_count, train_y, valid_y, valid_x = self.split_data()\n",
    "        accuracy, f1_score, model = self.train_model(naive_bayes.MultinomialNB(), xtrain_count, train_y, xvalid_count, valid_y)\n",
    "        return accuracy, f1_score, model\n",
    "    \n",
    "    #BernoulliNB()\n",
    "    def prediction1(self):\n",
    "        xtrain_count, xvalid_count, train_y, valid_y, valid_x = self.split_data()\n",
    "        accuracy, f1_score, model = self.train_model(naive_bayes.BernoulliNB(), xtrain_count, train_y, xvalid_count, valid_y)\n",
    "        return accuracy, f1_score, model\n",
    "    \n",
    "    #SVM\n",
    "    def prediction2(self):\n",
    "        xtrain_count, xvalid_count, train_y, valid_y, valid_x = self.split_data()\n",
    "        accuracy, f1_score, model = self.train_model(svm.LinearSVC(), xtrain_count, train_y, xvalid_count, valid_y)\n",
    "        return accuracy, f1_score, model\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_obj = Sentiment_analysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NAIVE BAYES - MULTINOMIAL \n",
    "accuracy, f1_score, model = sent_obj.prediction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.829, 0.814935064935065)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#NAIVE BAYES - MULTINOMIAL\n",
    "accuracy, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NAIVE BAYES - BERNOULLI\n",
    "accuracy1, f1_score1, model1 = sent_obj.prediction1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.838, 0.8287526427061311)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#NAIVE BAYES - BERNOULLI\n",
    "accuracy1, f1_score1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM\n",
    "accuracy2, f1_score2, model2 = sent_obj.prediction2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8385, 0.8323819408406851)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SVM \n",
    "accuracy2, f1_score2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
